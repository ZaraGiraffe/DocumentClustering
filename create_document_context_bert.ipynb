{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T11:32:29.494896200Z",
     "start_time": "2024-02-19T11:32:29.410613900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:48:37.416259400Z",
     "start_time": "2024-02-19T12:48:37.291074500Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.data import Lemmatizer\n",
    "from utils.loaders import DocDataset, DatasetUA\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:48:37.533939200Z",
     "start_time": "2024-02-19T12:48:37.447547500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T12:48:37.746249100Z",
     "start_time": "2024-02-19T12:48:37.651727300Z"
    }
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "from tqdm.auto import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "from utils.bert import get_embeddings_from_sentence, get_embeddings_from_document"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:48:37.872304700Z",
     "start_time": "2024-02-19T12:48:37.777804900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "from utils.clustering import BertHierarchicalClustering, BertCluster"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:50:09.048115500Z",
     "start_time": "2024-02-19T12:50:08.873682400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "doc_dataset = DocDataset(\"./DocDataset\", \"en\").load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:50:09.179902500Z",
     "start_time": "2024-02-19T12:50:09.048115500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['lang', 'source', 'filename', 'main_topic', 'text'],\n    num_rows: 20\n})"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:50:09.290096700Z",
     "start_time": "2024-02-19T12:50:09.201209600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6482e200d2cc4ca8b021dbbcf093c1e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "86426"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dataset.to_parquet(\"./doc.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:50:09.411738100Z",
     "start_time": "2024-02-19T12:50:09.319046100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "lemmatizer = Lemmatizer(\"en\")\n",
    "termins = json.load(open(\"termins.json\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:50:52.203540Z",
     "start_time": "2024-02-19T12:50:45.427248200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "['also',\n 'one',\n 'take',\n 'win',\n 'say',\n 'year',\n 'big',\n 'make',\n 'see',\n 'first',\n 'time',\n 'get',\n 'well',\n 'may',\n 'become',\n 'two',\n 'last',\n 'top',\n 'new',\n 'many',\n 'three',\n 'would',\n 'back',\n 'come',\n 'go',\n 'since',\n 'long',\n 'week',\n 'leave',\n 'far',\n 'could',\n 'still',\n 'people',\n 'point',\n 'five',\n 'remain',\n 'old',\n 'look',\n 'include',\n 'club',\n 'run',\n 'world',\n 'need',\n 'follow',\n 'league',\n 'past',\n 'home',\n 'put',\n 'city',\n 'expect']"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termins"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:50:52.849621600Z",
     "start_time": "2024-02-19T12:50:52.763280100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "numbers = list(range(20))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:50:55.969392600Z",
     "start_time": "2024-02-19T12:50:55.888627600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98373b53ebe64587ad0180cd1b5d994c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "51\n",
      "103\n",
      "29\n",
      "40\n",
      "85\n",
      "39\n",
      "87\n",
      "14\n",
      "22\n",
      "76\n",
      "77\n",
      "38\n",
      "34\n",
      "54\n",
      "43\n",
      "48\n",
      "92\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hierarchical_clustering = BertHierarchicalClustering(distance_type=\"euclidian\")\n",
    "\n",
    "for i in tqdm(numbers):\n",
    "    embeddings = get_embeddings_from_document(doc_dataset[i][\"text\"], model, tokenizer, lemmatizer, termins)\n",
    "    label = f\"[{i}] \" + doc_dataset[i][\"main_topic\"]\n",
    "    cluster = BertCluster(embeddings, i, label)\n",
    "    # print(cluster.labels, len(cluster.embeddings))\n",
    "    print(len(cluster.embeddings))\n",
    "    hierarchical_clustering.add_cluster(cluster)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:53:43.345497700Z",
     "start_time": "2024-02-19T12:52:47.882200800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[1] news']\n",
      "['[2] football']\n",
      "['[3] football']\n",
      "['[4] football']\n",
      "['[5] football']\n",
      "['[6] football']\n",
      "['[7] football']\n",
      "['[8] football']\n",
      "['[9] football']\n",
      "['[10] football']\n",
      "['[11] football']\n",
      "['[12] news']\n",
      "['[13] news']\n",
      "['[14] news']\n",
      "['[15] news']\n",
      "['[16] news']\n",
      "['[17] news']\n",
      "['[18] news']\n",
      "['[19] news', '[0] news']\n",
      "-------------------------------------------\n",
      "['[1] news']\n",
      "['[2] football']\n",
      "['[3] football']\n",
      "['[4] football']\n",
      "['[5] football']\n",
      "['[6] football']\n",
      "['[7] football']\n",
      "['[8] football']\n",
      "['[9] football']\n",
      "['[10] football']\n",
      "['[11] football']\n",
      "['[12] news']\n",
      "['[13] news']\n",
      "['[14] news']\n",
      "['[15] news']\n",
      "['[16] news']\n",
      "['[17] news']\n",
      "['[18] news', '[19] news', '[0] news']\n",
      "-------------------------------------------\n",
      "['[1] news']\n",
      "['[2] football']\n",
      "['[3] football']\n",
      "['[4] football']\n",
      "['[5] football']\n",
      "['[6] football']\n",
      "['[7] football']\n",
      "['[8] football']\n",
      "['[9] football']\n",
      "['[10] football']\n",
      "['[11] football']\n",
      "['[12] news']\n",
      "['[13] news']\n",
      "['[14] news']\n",
      "['[16] news']\n",
      "['[17] news']\n",
      "['[15] news', '[18] news', '[19] news', '[0] news']\n",
      "-------------------------------------------\n",
      "['[1] news']\n",
      "['[2] football']\n",
      "['[3] football']\n",
      "['[4] football']\n",
      "['[5] football']\n",
      "['[6] football']\n",
      "['[7] football']\n",
      "['[8] football']\n",
      "['[9] football']\n",
      "['[10] football']\n",
      "['[11] football']\n",
      "['[13] news']\n",
      "['[14] news']\n",
      "['[16] news']\n",
      "['[15] news', '[18] news', '[19] news', '[0] news']\n",
      "['[12] news', '[17] news']\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[109], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m18\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mhierarchical_clustering\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce_one_cluster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     clusters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(hierarchical_clustering\u001B[38;5;241m.\u001B[39mclusters\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m cluster \u001B[38;5;129;01min\u001B[39;00m clusters:\n",
      "File \u001B[1;32m~\\Desktop\\TextClustering\\utils\\clustering.py:187\u001B[0m, in \u001B[0;36mBertHierarchicalClustering.reduce_one_cluster\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete_cluster(cluster_id_1)\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete_cluster(cluster_id_2)\n\u001B[1;32m--> 187\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_cluster\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_cluster\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\TextClustering\\utils\\clustering.py:103\u001B[0m, in \u001B[0;36mBertHierarchicalClustering.add_cluster\u001B[1;34m(self, cluster)\u001B[0m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdist_mat[cluster_id][new_id] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 103\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdist_mat[cluster_id][new_id] \u001B[38;5;241m=\u001B[39m \u001B[43mBertHierarchicalClustering\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcluster_distance\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclusters\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcluster_id\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcluster\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\TextClustering\\utils\\clustering.py:126\u001B[0m, in \u001B[0;36mBertHierarchicalClustering.cluster_distance\u001B[1;34m(cluster1, cluster2, typ)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cluster1 \u001B[38;5;241m==\u001B[39m cluster2:\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m--> 126\u001B[0m distances \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mBertHierarchicalClustering\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvector_cluster_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcluster2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvector\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcluster1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39maverage(distances)\n",
      "File \u001B[1;32m~\\Desktop\\TextClustering\\utils\\clustering.py:127\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cluster1 \u001B[38;5;241m==\u001B[39m cluster2:\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m    126\u001B[0m distances \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m--> 127\u001B[0m     \u001B[43mBertHierarchicalClustering\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvector_cluster_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcluster2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m vector \u001B[38;5;129;01min\u001B[39;00m cluster1\u001B[38;5;241m.\u001B[39membeddings\n\u001B[0;32m    129\u001B[0m ]\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39maverage(distances)\n",
      "File \u001B[1;32m~\\Desktop\\TextClustering\\utils\\clustering.py:141\u001B[0m, in \u001B[0;36mBertHierarchicalClustering.vector_cluster_distance\u001B[1;34m(vector, cluster, typ)\u001B[0m\n\u001B[0;32m    139\u001B[0m distances \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cluster_vector \u001B[38;5;129;01min\u001B[39;00m cluster\u001B[38;5;241m.\u001B[39membeddings:\n\u001B[1;32m--> 141\u001B[0m     distance \u001B[38;5;241m=\u001B[39m \u001B[43mBertHierarchicalClustering\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvector_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcluster_vector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    142\u001B[0m     distances\u001B[38;5;241m.\u001B[39mappend(distance)\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39maverage(distances)\n",
      "File \u001B[1;32m~\\Desktop\\TextClustering\\utils\\clustering.py:152\u001B[0m, in \u001B[0;36mBertHierarchicalClustering.vector_distance\u001B[1;34m(vector1, vector2, typ)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;124;03m:param typ: string that specifies the type of distance to calculate: [\"cosine\", \"euclidian\"]\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;124;03m:return:\u001B[39;00m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meuclidian\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 152\u001B[0m     distance \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(\u001B[43m(\u001B[49m\u001B[43mvector1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mvector2\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m)\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meuclidian\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    154\u001B[0m     distance \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(vector1 \u001B[38;5;241m*\u001B[39m vector2) \u001B[38;5;241m/\u001B[39m \\\n\u001B[0;32m    155\u001B[0m                torch\u001B[38;5;241m.\u001B[39msqrt(torch\u001B[38;5;241m.\u001B[39msum(vector1 \u001B[38;5;241m*\u001B[39m vector1) \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(vector2 \u001B[38;5;241m*\u001B[39m vector2))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\speech2\\Lib\\site-packages\\torch\\_tensor.py:34\u001B[0m, in \u001B[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001B[39m(f):\n\u001B[0;32m     32\u001B[0m     assigned \u001B[38;5;241m=\u001B[39m functools\u001B[38;5;241m.\u001B[39mWRAPPER_ASSIGNMENTS\n\u001B[1;32m---> 34\u001B[0m     \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f, assigned\u001B[38;5;241m=\u001B[39massigned)\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     36\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     37\u001B[0m             \u001B[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001B[39;00m\n\u001B[0;32m     38\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m has_torch_function(args):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(18):\n",
    "    hierarchical_clustering.reduce_one_cluster()\n",
    "    clusters = list(hierarchical_clustering.clusters.values())\n",
    "    for cluster in clusters:\n",
    "        print(cluster.labels)\n",
    "    print(\"-------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T12:54:17.415981500Z",
     "start_time": "2024-02-19T12:54:07.267035700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clusters = list(hierarchical_clustering.clusters.values())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T09:26:06.144268900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for cluster in clusters:\n",
    "    print(cluster.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T09:26:06.145275400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
